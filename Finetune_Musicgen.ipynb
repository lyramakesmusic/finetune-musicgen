{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ikoib4YboTBY",
        "yG68hiK5vxA2",
        "us8clCVnv1IY",
        "9zlPbcLjv4qx",
        "UjevANVKv_dw"
      ],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XelDA1GGvaXw"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/audiocraft.git\n",
        "%cd audiocraft\n",
        "!pip install -e .\n",
        "!pip install dora-search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚠️ read the whole notebook first! ⚠️\n",
        "There's high odds that your question is already answered somewhere in here. pay attention to details like file paths, and skim through the example code. make sure you understand it before diving face first into a training run!"
      ],
      "metadata": {
        "id": "Hajimhie5Plf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data preprocessing etc\n",
        "\n",
        "### --- this is optional if you've already got resampled 30s audio clips and .json labels ---\n",
        "\n",
        "This section includes a tool to slice your audio into 30s chunks, resample to 44100hz, and normalize. it also includes a WIP autolabeller based on essentia (https://essentia.upf.edu/models.html, https://colab.research.google.com/drive/1tFInmCYK2uX-PajYemERvtSojkT0vrhF)\n",
        "\n",
        "If you don't want to autolabel your data but you do want to split it, only run the first cell under this header. The rest is for essentia.\n",
        "\n",
        "Tags parsed by essentia:\n",
        "- genre\n",
        "- mood/theme\n",
        "- instrumentation\n",
        "- key, bpm (these are actually from librosa)\n",
        "\n",
        "This section is very WIP, and it's always better to label your own data. However, that can be a lot of work especially with a lot of samples. this should give you a decent baseline.\n",
        "\n",
        "> TODO: for the autolabeller to have best results, you provide an OpenAI API key when prompted so it can do some prompt enhancement on the tags essentia creates. Otherwise, it will train only on the raw tags. information TBA by GPT:\n",
        "> - natural language description\n",
        "> - enhanced tags (eg adding \"percussion\" if \"drums\" already exists)\n",
        "\n",
        "> TODO: add a song recognition API to fill in title and artist info\n",
        "\n",
        "> TODO: figure out vram requirements, and clean up to leave space for musicgen. for now, save the `.jsonl` files, restart the notebook (your split files should be safe in drive), run everything after this (replacing the `.jsonl` files with the ones you downloaded at the paths mentioned in the code), and you should be okay."
      ],
      "metadata": {
        "id": "ikoib4YboTBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mount google drive to access dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/samples/train_musicgen_edm_uncond/train/outputs\""
      ],
      "metadata": {
        "id": "vZpD62WSvICH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split and resample\n",
        "\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "os.makedirs(os.path.join(dataset_path, \"original\"), exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(dataset_path):\n",
        "    if filename.endswith(('.mp3', '.wav', '.flac')):\n",
        "\n",
        "        # move original file out of the way\n",
        "        os.rename(filename, f\"original/{filename}\")\n",
        "        audio = AudioSegment.from_file(f\"original/{filename}\")\n",
        "\n",
        "        # resample\n",
        "        audio = audio.set_frame_rate(44100)\n",
        "\n",
        "        # split into 30-second chunks\n",
        "        for i in range(0, len(audio), 30000):\n",
        "            chunk = audio[i:i+30000]\n",
        "            chunk.export(f\"{filename[:-4]}_chunk{i//1000}.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "id": "wuIIBXApr2Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install essentia and requirements\n",
        "\n",
        "# this line is needed for the tensorflow modules to install properly!!\n",
        "!sudo apt-get install build-essential libeigen3-dev libyaml-dev libfftw3-dev libtag1-dev libchromaprint-dev\n",
        "\n",
        "!pip install -U essentia-tensorflow"
      ],
      "metadata": {
        "id": "J0lknCOjoSAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download some essentia model weights\n",
        "\n",
        "!curl https://essentia.upf.edu/models/classification-heads/genre_discogs400/genre_discogs400-discogs-effnet-1.pb --output genre_discogs400-discogs-effnet-1.pb\n",
        "!curl https://essentia.upf.edu/models/feature-extractors/discogs-effnet/discogs-effnet-bs64-1.pb --output discogs-effnet-bs64-1.pb\n",
        "!curl https://essentia.upf.edu/models/classification-heads/mtg_jamendo_moodtheme/mtg_jamendo_moodtheme-discogs-effnet-1.pb --output mtg_jamendo_moodtheme-discogs-effnet-1.pb\n",
        "!curl https://essentia.upf.edu/models/classification-heads/mtg_jamendo_instrument/mtg_jamendo_instrument-discogs-effnet-1.pb --output mtg_jamendo_instrument-discogs-effnet-1.pb"
      ],
      "metadata": {
        "id": "Q7gZlO_rqnQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title metadata (labels) for essentia - LONG CELL DONT OPEN\n",
        "genre_labels = [\n",
        "    \"Blues---Boogie Woogie\",\n",
        "    \"Blues---Chicago Blues\",\n",
        "    \"Blues---Country Blues\",\n",
        "    \"Blues---Delta Blues\",\n",
        "    \"Blues---Electric Blues\",\n",
        "    \"Blues---Harmonica Blues\",\n",
        "    \"Blues---Jump Blues\",\n",
        "    \"Blues---Louisiana Blues\",\n",
        "    \"Blues---Modern Electric Blues\",\n",
        "    \"Blues---Piano Blues\",\n",
        "    \"Blues---Rhythm & Blues\",\n",
        "    \"Blues---Texas Blues\",\n",
        "    \"Brass & Military---Brass Band\",\n",
        "    \"Brass & Military---Marches\",\n",
        "    \"Brass & Military---Military\",\n",
        "    \"Children's---Educational\",\n",
        "    \"Children's---Nursery Rhymes\",\n",
        "    \"Children's---Story\",\n",
        "    \"Classical---Baroque\",\n",
        "    \"Classical---Choral\",\n",
        "    \"Classical---Classical\",\n",
        "    \"Classical---Contemporary\",\n",
        "    \"Classical---Impressionist\",\n",
        "    \"Classical---Medieval\",\n",
        "    \"Classical---Modern\",\n",
        "    \"Classical---Neo-Classical\",\n",
        "    \"Classical---Neo-Romantic\",\n",
        "    \"Classical---Opera\",\n",
        "    \"Classical---Post-Modern\",\n",
        "    \"Classical---Renaissance\",\n",
        "    \"Classical---Romantic\",\n",
        "    \"Electronic---Abstract\",\n",
        "    \"Electronic---Acid\",\n",
        "    \"Electronic---Acid House\",\n",
        "    \"Electronic---Acid Jazz\",\n",
        "    \"Electronic---Ambient\",\n",
        "    \"Electronic---Bassline\",\n",
        "    \"Electronic---Beatdown\",\n",
        "    \"Electronic---Berlin-School\",\n",
        "    \"Electronic---Big Beat\",\n",
        "    \"Electronic---Bleep\",\n",
        "    \"Electronic---Breakbeat\",\n",
        "    \"Electronic---Breakcore\",\n",
        "    \"Electronic---Breaks\",\n",
        "    \"Electronic---Broken Beat\",\n",
        "    \"Electronic---Chillwave\",\n",
        "    \"Electronic---Chiptune\",\n",
        "    \"Electronic---Dance-pop\",\n",
        "    \"Electronic---Dark Ambient\",\n",
        "    \"Electronic---Darkwave\",\n",
        "    \"Electronic---Deep House\",\n",
        "    \"Electronic---Deep Techno\",\n",
        "    \"Electronic---Disco\",\n",
        "    \"Electronic---Disco Polo\",\n",
        "    \"Electronic---Donk\",\n",
        "    \"Electronic---Downtempo\",\n",
        "    \"Electronic---Drone\",\n",
        "    \"Electronic---Drum n Bass\",\n",
        "    \"Electronic---Dub\",\n",
        "    \"Electronic---Dub Techno\",\n",
        "    \"Electronic---Dubstep\",\n",
        "    \"Electronic---Dungeon Synth\",\n",
        "    \"Electronic---EBM\",\n",
        "    \"Electronic---Electro\",\n",
        "    \"Electronic---Electro House\",\n",
        "    \"Electronic---Electroclash\",\n",
        "    \"Electronic---Euro House\",\n",
        "    \"Electronic---Euro-Disco\",\n",
        "    \"Electronic---Eurobeat\",\n",
        "    \"Electronic---Eurodance\",\n",
        "    \"Electronic---Experimental\",\n",
        "    \"Electronic---Freestyle\",\n",
        "    \"Electronic---Future Jazz\",\n",
        "    \"Electronic---Gabber\",\n",
        "    \"Electronic---Garage House\",\n",
        "    \"Electronic---Ghetto\",\n",
        "    \"Electronic---Ghetto House\",\n",
        "    \"Electronic---Glitch\",\n",
        "    \"Electronic---Goa Trance\",\n",
        "    \"Electronic---Grime\",\n",
        "    \"Electronic---Halftime\",\n",
        "    \"Electronic---Hands Up\",\n",
        "    \"Electronic---Happy Hardcore\",\n",
        "    \"Electronic---Hard House\",\n",
        "    \"Electronic---Hard Techno\",\n",
        "    \"Electronic---Hard Trance\",\n",
        "    \"Electronic---Hardcore\",\n",
        "    \"Electronic---Hardstyle\",\n",
        "    \"Electronic---Hi NRG\",\n",
        "    \"Electronic---Hip Hop\",\n",
        "    \"Electronic---Hip-House\",\n",
        "    \"Electronic---House\",\n",
        "    \"Electronic---IDM\",\n",
        "    \"Electronic---Illbient\",\n",
        "    \"Electronic---Industrial\",\n",
        "    \"Electronic---Italo House\",\n",
        "    \"Electronic---Italo-Disco\",\n",
        "    \"Electronic---Italodance\",\n",
        "    \"Electronic---Jazzdance\",\n",
        "    \"Electronic---Juke\",\n",
        "    \"Electronic---Jumpstyle\",\n",
        "    \"Electronic---Jungle\",\n",
        "    \"Electronic---Latin\",\n",
        "    \"Electronic---Leftfield\",\n",
        "    \"Electronic---Makina\",\n",
        "    \"Electronic---Minimal\",\n",
        "    \"Electronic---Minimal Techno\",\n",
        "    \"Electronic---Modern Classical\",\n",
        "    \"Electronic---Musique Concrète\",\n",
        "    \"Electronic---Neofolk\",\n",
        "    \"Electronic---New Age\",\n",
        "    \"Electronic---New Beat\",\n",
        "    \"Electronic---New Wave\",\n",
        "    \"Electronic---Noise\",\n",
        "    \"Electronic---Nu-Disco\",\n",
        "    \"Electronic---Power Electronics\",\n",
        "    \"Electronic---Progressive Breaks\",\n",
        "    \"Electronic---Progressive House\",\n",
        "    \"Electronic---Progressive Trance\",\n",
        "    \"Electronic---Psy-Trance\",\n",
        "    \"Electronic---Rhythmic Noise\",\n",
        "    \"Electronic---Schranz\",\n",
        "    \"Electronic---Sound Collage\",\n",
        "    \"Electronic---Speed Garage\",\n",
        "    \"Electronic---Speedcore\",\n",
        "    \"Electronic---Synth-pop\",\n",
        "    \"Electronic---Synthwave\",\n",
        "    \"Electronic---Tech House\",\n",
        "    \"Electronic---Tech Trance\",\n",
        "    \"Electronic---Techno\",\n",
        "    \"Electronic---Trance\",\n",
        "    \"Electronic---Tribal\",\n",
        "    \"Electronic---Tribal House\",\n",
        "    \"Electronic---Trip Hop\",\n",
        "    \"Electronic---Tropical House\",\n",
        "    \"Electronic---UK Garage\",\n",
        "    \"Electronic---Vaporwave\",\n",
        "    \"Folk, World, & Country---African\",\n",
        "    \"Folk, World, & Country---Bluegrass\",\n",
        "    \"Folk, World, & Country---Cajun\",\n",
        "    \"Folk, World, & Country---Canzone Napoletana\",\n",
        "    \"Folk, World, & Country---Catalan Music\",\n",
        "    \"Folk, World, & Country---Celtic\",\n",
        "    \"Folk, World, & Country---Country\",\n",
        "    \"Folk, World, & Country---Fado\",\n",
        "    \"Folk, World, & Country---Flamenco\",\n",
        "    \"Folk, World, & Country---Folk\",\n",
        "    \"Folk, World, & Country---Gospel\",\n",
        "    \"Folk, World, & Country---Highlife\",\n",
        "    \"Folk, World, & Country---Hillbilly\",\n",
        "    \"Folk, World, & Country---Hindustani\",\n",
        "    \"Folk, World, & Country---Honky Tonk\",\n",
        "    \"Folk, World, & Country---Indian Classical\",\n",
        "    \"Folk, World, & Country---Laïkó\",\n",
        "    \"Folk, World, & Country---Nordic\",\n",
        "    \"Folk, World, & Country---Pacific\",\n",
        "    \"Folk, World, & Country---Polka\",\n",
        "    \"Folk, World, & Country---Raï\",\n",
        "    \"Folk, World, & Country---Romani\",\n",
        "    \"Folk, World, & Country---Soukous\",\n",
        "    \"Folk, World, & Country---Séga\",\n",
        "    \"Folk, World, & Country---Volksmusik\",\n",
        "    \"Folk, World, & Country---Zouk\",\n",
        "    \"Folk, World, & Country---Éntekhno\",\n",
        "    \"Funk / Soul---Afrobeat\",\n",
        "    \"Funk / Soul---Boogie\",\n",
        "    \"Funk / Soul---Contemporary R&B\",\n",
        "    \"Funk / Soul---Disco\",\n",
        "    \"Funk / Soul---Free Funk\",\n",
        "    \"Funk / Soul---Funk\",\n",
        "    \"Funk / Soul---Gospel\",\n",
        "    \"Funk / Soul---Neo Soul\",\n",
        "    \"Funk / Soul---New Jack Swing\",\n",
        "    \"Funk / Soul---P.Funk\",\n",
        "    \"Funk / Soul---Psychedelic\",\n",
        "    \"Funk / Soul---Rhythm & Blues\",\n",
        "    \"Funk / Soul---Soul\",\n",
        "    \"Funk / Soul---Swingbeat\",\n",
        "    \"Funk / Soul---UK Street Soul\",\n",
        "    \"Hip Hop---Bass Music\",\n",
        "    \"Hip Hop---Boom Bap\",\n",
        "    \"Hip Hop---Bounce\",\n",
        "    \"Hip Hop---Britcore\",\n",
        "    \"Hip Hop---Cloud Rap\",\n",
        "    \"Hip Hop---Conscious\",\n",
        "    \"Hip Hop---Crunk\",\n",
        "    \"Hip Hop---Cut-up/DJ\",\n",
        "    \"Hip Hop---DJ Battle Tool\",\n",
        "    \"Hip Hop---Electro\",\n",
        "    \"Hip Hop---G-Funk\",\n",
        "    \"Hip Hop---Gangsta\",\n",
        "    \"Hip Hop---Grime\",\n",
        "    \"Hip Hop---Hardcore Hip-Hop\",\n",
        "    \"Hip Hop---Horrorcore\",\n",
        "    \"Hip Hop---Instrumental\",\n",
        "    \"Hip Hop---Jazzy Hip-Hop\",\n",
        "    \"Hip Hop---Miami Bass\",\n",
        "    \"Hip Hop---Pop Rap\",\n",
        "    \"Hip Hop---Ragga HipHop\",\n",
        "    \"Hip Hop---RnB/Swing\",\n",
        "    \"Hip Hop---Screw\",\n",
        "    \"Hip Hop---Thug Rap\",\n",
        "    \"Hip Hop---Trap\",\n",
        "    \"Hip Hop---Trip Hop\",\n",
        "    \"Hip Hop---Turntablism\",\n",
        "    \"Jazz---Afro-Cuban Jazz\",\n",
        "    \"Jazz---Afrobeat\",\n",
        "    \"Jazz---Avant-garde Jazz\",\n",
        "    \"Jazz---Big Band\",\n",
        "    \"Jazz---Bop\",\n",
        "    \"Jazz---Bossa Nova\",\n",
        "    \"Jazz---Contemporary Jazz\",\n",
        "    \"Jazz---Cool Jazz\",\n",
        "    \"Jazz---Dixieland\",\n",
        "    \"Jazz---Easy Listening\",\n",
        "    \"Jazz---Free Improvisation\",\n",
        "    \"Jazz---Free Jazz\",\n",
        "    \"Jazz---Fusion\",\n",
        "    \"Jazz---Gypsy Jazz\",\n",
        "    \"Jazz---Hard Bop\",\n",
        "    \"Jazz---Jazz-Funk\",\n",
        "    \"Jazz---Jazz-Rock\",\n",
        "    \"Jazz---Latin Jazz\",\n",
        "    \"Jazz---Modal\",\n",
        "    \"Jazz---Post Bop\",\n",
        "    \"Jazz---Ragtime\",\n",
        "    \"Jazz---Smooth Jazz\",\n",
        "    \"Jazz---Soul-Jazz\",\n",
        "    \"Jazz---Space-Age\",\n",
        "    \"Jazz---Swing\",\n",
        "    \"Latin---Afro-Cuban\",\n",
        "    \"Latin---Baião\",\n",
        "    \"Latin---Batucada\",\n",
        "    \"Latin---Beguine\",\n",
        "    \"Latin---Bolero\",\n",
        "    \"Latin---Boogaloo\",\n",
        "    \"Latin---Bossanova\",\n",
        "    \"Latin---Cha-Cha\",\n",
        "    \"Latin---Charanga\",\n",
        "    \"Latin---Compas\",\n",
        "    \"Latin---Cubano\",\n",
        "    \"Latin---Cumbia\",\n",
        "    \"Latin---Descarga\",\n",
        "    \"Latin---Forró\",\n",
        "    \"Latin---Guaguancó\",\n",
        "    \"Latin---Guajira\",\n",
        "    \"Latin---Guaracha\",\n",
        "    \"Latin---MPB\",\n",
        "    \"Latin---Mambo\",\n",
        "    \"Latin---Mariachi\",\n",
        "    \"Latin---Merengue\",\n",
        "    \"Latin---Norteño\",\n",
        "    \"Latin---Nueva Cancion\",\n",
        "    \"Latin---Pachanga\",\n",
        "    \"Latin---Porro\",\n",
        "    \"Latin---Ranchera\",\n",
        "    \"Latin---Reggaeton\",\n",
        "    \"Latin---Rumba\",\n",
        "    \"Latin---Salsa\",\n",
        "    \"Latin---Samba\",\n",
        "    \"Latin---Son\",\n",
        "    \"Latin---Son Montuno\",\n",
        "    \"Latin---Tango\",\n",
        "    \"Latin---Tejano\",\n",
        "    \"Latin---Vallenato\",\n",
        "    \"Non-Music---Audiobook\",\n",
        "    \"Non-Music---Comedy\",\n",
        "    \"Non-Music---Dialogue\",\n",
        "    \"Non-Music---Education\",\n",
        "    \"Non-Music---Field Recording\",\n",
        "    \"Non-Music---Interview\",\n",
        "    \"Non-Music---Monolog\",\n",
        "    \"Non-Music---Poetry\",\n",
        "    \"Non-Music---Political\",\n",
        "    \"Non-Music---Promotional\",\n",
        "    \"Non-Music---Radioplay\",\n",
        "    \"Non-Music---Religious\",\n",
        "    \"Non-Music---Spoken Word\",\n",
        "    \"Pop---Ballad\",\n",
        "    \"Pop---Bollywood\",\n",
        "    \"Pop---Bubblegum\",\n",
        "    \"Pop---Chanson\",\n",
        "    \"Pop---City Pop\",\n",
        "    \"Pop---Europop\",\n",
        "    \"Pop---Indie Pop\",\n",
        "    \"Pop---J-pop\",\n",
        "    \"Pop---K-pop\",\n",
        "    \"Pop---Kayōkyoku\",\n",
        "    \"Pop---Light Music\",\n",
        "    \"Pop---Music Hall\",\n",
        "    \"Pop---Novelty\",\n",
        "    \"Pop---Parody\",\n",
        "    \"Pop---Schlager\",\n",
        "    \"Pop---Vocal\",\n",
        "    \"Reggae---Calypso\",\n",
        "    \"Reggae---Dancehall\",\n",
        "    \"Reggae---Dub\",\n",
        "    \"Reggae---Lovers Rock\",\n",
        "    \"Reggae---Ragga\",\n",
        "    \"Reggae---Reggae\",\n",
        "    \"Reggae---Reggae-Pop\",\n",
        "    \"Reggae---Rocksteady\",\n",
        "    \"Reggae---Roots Reggae\",\n",
        "    \"Reggae---Ska\",\n",
        "    \"Reggae---Soca\",\n",
        "    \"Rock---AOR\",\n",
        "    \"Rock---Acid Rock\",\n",
        "    \"Rock---Acoustic\",\n",
        "    \"Rock---Alternative Rock\",\n",
        "    \"Rock---Arena Rock\",\n",
        "    \"Rock---Art Rock\",\n",
        "    \"Rock---Atmospheric Black Metal\",\n",
        "    \"Rock---Avantgarde\",\n",
        "    \"Rock---Beat\",\n",
        "    \"Rock---Black Metal\",\n",
        "    \"Rock---Blues Rock\",\n",
        "    \"Rock---Brit Pop\",\n",
        "    \"Rock---Classic Rock\",\n",
        "    \"Rock---Coldwave\",\n",
        "    \"Rock---Country Rock\",\n",
        "    \"Rock---Crust\",\n",
        "    \"Rock---Death Metal\",\n",
        "    \"Rock---Deathcore\",\n",
        "    \"Rock---Deathrock\",\n",
        "    \"Rock---Depressive Black Metal\",\n",
        "    \"Rock---Doo Wop\",\n",
        "    \"Rock---Doom Metal\",\n",
        "    \"Rock---Dream Pop\",\n",
        "    \"Rock---Emo\",\n",
        "    \"Rock---Ethereal\",\n",
        "    \"Rock---Experimental\",\n",
        "    \"Rock---Folk Metal\",\n",
        "    \"Rock---Folk Rock\",\n",
        "    \"Rock---Funeral Doom Metal\",\n",
        "    \"Rock---Funk Metal\",\n",
        "    \"Rock---Garage Rock\",\n",
        "    \"Rock---Glam\",\n",
        "    \"Rock---Goregrind\",\n",
        "    \"Rock---Goth Rock\",\n",
        "    \"Rock---Gothic Metal\",\n",
        "    \"Rock---Grindcore\",\n",
        "    \"Rock---Grunge\",\n",
        "    \"Rock---Hard Rock\",\n",
        "    \"Rock---Hardcore\",\n",
        "    \"Rock---Heavy Metal\",\n",
        "    \"Rock---Indie Rock\",\n",
        "    \"Rock---Industrial\",\n",
        "    \"Rock---Krautrock\",\n",
        "    \"Rock---Lo-Fi\",\n",
        "    \"Rock---Lounge\",\n",
        "    \"Rock---Math Rock\",\n",
        "    \"Rock---Melodic Death Metal\",\n",
        "    \"Rock---Melodic Hardcore\",\n",
        "    \"Rock---Metalcore\",\n",
        "    \"Rock---Mod\",\n",
        "    \"Rock---Neofolk\",\n",
        "    \"Rock---New Wave\",\n",
        "    \"Rock---No Wave\",\n",
        "    \"Rock---Noise\",\n",
        "    \"Rock---Noisecore\",\n",
        "    \"Rock---Nu Metal\",\n",
        "    \"Rock---Oi\",\n",
        "    \"Rock---Parody\",\n",
        "    \"Rock---Pop Punk\",\n",
        "    \"Rock---Pop Rock\",\n",
        "    \"Rock---Pornogrind\",\n",
        "    \"Rock---Post Rock\",\n",
        "    \"Rock---Post-Hardcore\",\n",
        "    \"Rock---Post-Metal\",\n",
        "    \"Rock---Post-Punk\",\n",
        "    \"Rock---Power Metal\",\n",
        "    \"Rock---Power Pop\",\n",
        "    \"Rock---Power Violence\",\n",
        "    \"Rock---Prog Rock\",\n",
        "    \"Rock---Progressive Metal\",\n",
        "    \"Rock---Psychedelic Rock\",\n",
        "    \"Rock---Psychobilly\",\n",
        "    \"Rock---Pub Rock\",\n",
        "    \"Rock---Punk\",\n",
        "    \"Rock---Rock & Roll\",\n",
        "    \"Rock---Rockabilly\",\n",
        "    \"Rock---Shoegaze\",\n",
        "    \"Rock---Ska\",\n",
        "    \"Rock---Sludge Metal\",\n",
        "    \"Rock---Soft Rock\",\n",
        "    \"Rock---Southern Rock\",\n",
        "    \"Rock---Space Rock\",\n",
        "    \"Rock---Speed Metal\",\n",
        "    \"Rock---Stoner Rock\",\n",
        "    \"Rock---Surf\",\n",
        "    \"Rock---Symphonic Rock\",\n",
        "    \"Rock---Technical Death Metal\",\n",
        "    \"Rock---Thrash\",\n",
        "    \"Rock---Twist\",\n",
        "    \"Rock---Viking Metal\",\n",
        "    \"Rock---Yé-Yé\",\n",
        "    \"Stage & Screen---Musical\",\n",
        "    \"Stage & Screen---Score\",\n",
        "    \"Stage & Screen---Soundtrack\",\n",
        "    \"Stage & Screen---Theme\",\n",
        "]\n",
        "mood_theme_classes = [\n",
        "    \"action\",\n",
        "    \"adventure\",\n",
        "    \"advertising\",\n",
        "    \"background\",\n",
        "    \"ballad\",\n",
        "    \"calm\",\n",
        "    \"children\",\n",
        "    \"christmas\",\n",
        "    \"commercial\",\n",
        "    \"cool\",\n",
        "    \"corporate\",\n",
        "    \"dark\",\n",
        "    \"deep\",\n",
        "    \"documentary\",\n",
        "    \"drama\",\n",
        "    \"dramatic\",\n",
        "    \"dream\",\n",
        "    \"emotional\",\n",
        "    \"energetic\",\n",
        "    \"epic\",\n",
        "    \"fast\",\n",
        "    \"film\",\n",
        "    \"fun\",\n",
        "    \"funny\",\n",
        "    \"game\",\n",
        "    \"groovy\",\n",
        "    \"happy\",\n",
        "    \"heavy\",\n",
        "    \"holiday\",\n",
        "    \"hopeful\",\n",
        "    \"inspiring\",\n",
        "    \"love\",\n",
        "    \"meditative\",\n",
        "    \"melancholic\",\n",
        "    \"melodic\",\n",
        "    \"motivational\",\n",
        "    \"movie\",\n",
        "    \"nature\",\n",
        "    \"party\",\n",
        "    \"positive\",\n",
        "    \"powerful\",\n",
        "    \"relaxing\",\n",
        "    \"retro\",\n",
        "    \"romantic\",\n",
        "    \"sad\",\n",
        "    \"sexy\",\n",
        "    \"slow\",\n",
        "    \"soft\",\n",
        "    \"soundscape\",\n",
        "    \"space\",\n",
        "    \"sport\",\n",
        "    \"summer\",\n",
        "    \"trailer\",\n",
        "    \"travel\",\n",
        "    \"upbeat\",\n",
        "    \"uplifting\"\n",
        "]\n",
        "instrument_classes = [\n",
        "    \"accordion\",\n",
        "    \"acousticbassguitar\",\n",
        "    \"acousticguitar\",\n",
        "    \"bass\",\n",
        "    \"beat\",\n",
        "    \"bell\",\n",
        "    \"bongo\",\n",
        "    \"brass\",\n",
        "    \"cello\",\n",
        "    \"clarinet\",\n",
        "    \"classicalguitar\",\n",
        "    \"computer\",\n",
        "    \"doublebass\",\n",
        "    \"drummachine\",\n",
        "    \"drums\",\n",
        "    \"electricguitar\",\n",
        "    \"electricpiano\",\n",
        "    \"flute\",\n",
        "    \"guitar\",\n",
        "    \"harmonica\",\n",
        "    \"harp\",\n",
        "    \"horn\",\n",
        "    \"keyboard\",\n",
        "    \"oboe\",\n",
        "    \"orchestra\",\n",
        "    \"organ\",\n",
        "    \"pad\",\n",
        "    \"percussion\",\n",
        "    \"piano\",\n",
        "    \"pipeorgan\",\n",
        "    \"rhodes\",\n",
        "    \"sampler\",\n",
        "    \"saxophone\",\n",
        "    \"strings\",\n",
        "    \"synthesizer\",\n",
        "    \"trombone\",\n",
        "    \"trumpet\",\n",
        "    \"viola\",\n",
        "    \"violin\",\n",
        "    \"voice\"\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1JX_9JaIquIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D\n",
        "import numpy as np\n",
        "\n",
        "def get_audio_features(audio_filename):\n",
        "    audio = MonoLoader(filename=audio_filename, sampleRate=16000, resampleQuality=4)()\n",
        "    embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=\"discogs-effnet-bs64-1.pb\", output=\"PartitionedCall:1\")\n",
        "    embeddings = embedding_model(audio)\n",
        "\n",
        "    def filter_predictions(predictions, class_list, threshold=0.1):\n",
        "        predictions_mean = np.mean(predictions, axis=0)\n",
        "        sorted_indices = np.argsort(predictions_mean)[::-1]\n",
        "        filtered_indices = [i for i in sorted_indices if predictions_mean[i] > threshold]\n",
        "        filtered_labels = [class_list[i] for i in filtered_indices]\n",
        "        filtered_values = [predictions_mean[i] for i in filtered_indices]\n",
        "        return filtered_labels, filtered_values\n",
        "\n",
        "    def make_comma_separated_unique(tags):\n",
        "        seen_tags = set()\n",
        "        result = []\n",
        "        for tag in ', '.join(tags).split(', '):\n",
        "            if tag not in seen_tags:\n",
        "                result.append(tag)\n",
        "                seen_tags.add(tag)\n",
        "        return ', '.join(result)\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    # predict genres\n",
        "    model = TensorflowPredict2D(graphFilename=\"genre_discogs400-discogs-effnet-1.pb\", input=\"serving_default_model_Placeholder\", output=\"PartitionedCall:0\")\n",
        "    predictions = model(embeddings)\n",
        "    filtered_labels, _ = filter_predictions(predictions, genre_labels)\n",
        "    filtered_labels = ', '.join(filtered_labels).replace(\"---\", \", \").split(', ')\n",
        "    result_dict['genres'] = make_comma_separated_unique(filtered_labels)\n",
        "\n",
        "    # predict mood/theme\n",
        "    model = TensorflowPredict2D(graphFilename=\"mtg_jamendo_moodtheme-discogs-effnet-1.pb\")\n",
        "    predictions = model(embeddings)\n",
        "    filtered_labels, _ = filter_predictions(predictions, mood_theme_classes, threshold=0.05)\n",
        "    result_dict['moods'] = make_comma_separated_unique(filtered_labels)\n",
        "\n",
        "    # predict instruments\n",
        "    model = TensorflowPredict2D(graphFilename=\"mtg_jamendo_instrument-discogs-effnet-1.pb\")\n",
        "    predictions = model(embeddings)\n",
        "    filtered_labels, _ = filter_predictions(predictions, instrument_classes)\n",
        "    result_dict['instruments'] = filtered_labels\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "MT2zxVBYrBQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .jsonl from the extracted features, make a train/test split, and save in the right place.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# make sure the .jsonl has a place to go\n",
        "os.makedirs(\"/content/audiocraft/egs/train\", exist_ok=True)\n",
        "os.makedirs(\"/content/audiocraft/egs/eval\", exist_ok=True)\n",
        "\n",
        "train_len = 0\n",
        "eval_len = 0\n",
        "\n",
        "with open(\"/content/audiocraft/egs/train/data.jsonl\", \"w\") as train_file, \\\n",
        "     open(\"/content/audiocraft/egs/eval/data.jsonl\", \"w\") as eval_file:\n",
        "\n",
        "    for filename in os.listdir(dataset_path):\n",
        "        result = get_audio_features(os.path.join(dataset_path, filename))\n",
        "        print(f\"{filename}: {result}\")\n",
        "\n",
        "        # TODO: make openai call, populate description and keywords\n",
        "\n",
        "        # get key and BPM\n",
        "        y, sr = librosa.load(audio_path)\n",
        "        tempo, _ = librosa.beat.beat_track(y, sr=sr)\n",
        "        audio = AudioSegment.from_file(audio_path, format=os.path.splitext(filename)[1][1:])\n",
        "        samples = audio.get_array_of_samples()\n",
        "        key = librosa.key(samples, sr=sr)\n",
        "        print(f\"{filename}: detected key {key}, detected bpm {tempo}\")\n",
        "\n",
        "        # populate json\n",
        "        entry = {\n",
        "            \"key\": f\"{key}\",\n",
        "            \"artist\": \"\",\n",
        "            \"sample_rate\": 44100,\n",
        "            \"file_extension\": \"wav\",\n",
        "            \"description\": \"\",\n",
        "            \"keywords\": \"\",\n",
        "            \"duration\": 30.0,\n",
        "            \"bpm\": round(tempo),\n",
        "            \"genre\": result.get('genres', \"\"),\n",
        "            \"title\": \"\",\n",
        "            \"name\": \"\",\n",
        "            \"instrument\": result.get('instruments', \"\"),\n",
        "            \"moods\": result.get('moods', []),\n",
        "            \"path\": os.path.join(dataset_path, filename),\n",
        "        }\n",
        "\n",
        "        # train/test split\n",
        "        if random.random() < 0.85:\n",
        "            train_len += 1\n",
        "            train_file.write(json.dumps(entry) + '\\n')\n",
        "        else:\n",
        "            eval_len += 1\n",
        "            eval_file.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "print(train_len)\n",
        "print(eval_len)\n",
        "\n",
        "# this makes the next cell that tries to write .jsonl get skipped\n",
        "autolabelled = True"
      ],
      "metadata": {
        "id": "2yN_ar3rrm86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dataset into musicgen\n",
        "\n",
        "a dataset for musicgen is:\n",
        "- a .yaml file with basic info about the audio sample rate and channels, and a pointer to .jsonl files containing the prompt metadata and links to the corresponding audio files.\n",
        "- the above .jsonl file\n",
        "- a folder full of audio\n",
        "\n",
        "it looks for the .yaml at `content/audiocraft/config/dset/audio/YOUR_TRAINING_RUN.yaml`, which you point to by setting `dset=audio/YOUR_TRAINING_RUN` in the `dora run` command. In my case, `YOUR_TRAINING_RUN` is `train` in the example code.\n",
        "\n",
        "it looks like this:\n",
        "```\n",
        "datasource:\n",
        "  max_channels: 2\n",
        "  max_sample_rate: 44100\n",
        "\n",
        "  evaluate: egs/eval\n",
        "  generate: egs/train\n",
        "  train: egs/train\n",
        "  valid: egs/eval\n",
        "```\n",
        "you can use four different datasets, but it works just fine (if you're okay with overfitting!) with all of them pointing to the same one.\n",
        "\n",
        "The script is currently set up to put 15% of your dataset in `egs/eval` at random. This should help mitigate overfitting.\n",
        "\n",
        "- `train`: Data for training the model.\n",
        "- `valid`: Data for hyperparameter tuning and early stopping during training.\n",
        "- `evaluate`: Data for assessing the model's performance post-training.\n",
        "- `generate`: Data used for output generation, often the same as `train` but not necessarily.\n",
        "\n",
        "the `egs/YOUR_TRAINING_RUN` is referring to `content/audiocraft/egs/YOUR_TRAINING_RUN/data.jsonl`. the contents is a long list of lines that each look like this:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"key\": \"\", \"artist\": \"\", \"sample_rate\": 44100, \"file_extension\": \"wav\",\n",
        "  \"description\": \"\", \"keywords\": \"\", \"duration\": 30.0, \"bpm\": \"\", \"genre\": \"\",\n",
        "  \"title\": \"\", \"name\": \"\", \"instrument\": \"\", \"moods\": [],\n",
        "  \"path\": os.path.join(dataset_folder, filename),\n",
        "}\n",
        "```\n",
        "any of these fields will be omitted if empty, only \"path\" is required.\n",
        "\n",
        "If you already have json tags for your dataset (eg: `filename1.wav` `filename1.json`, `filename2.wav` `filename2.json`), set `use_existing_json` to `True` in the following code. Otherwise, it will use a blank json template for all the files, as an example.\n",
        "\n",
        "## example:\n",
        "\n",
        "the below code is what I used to construct my dataset. it depends on a few assumptions about it, namely:\n",
        "- all the audios are 30 seconds long @ 44100 samples\n",
        "- they live in `content/drive/MyDrive/samples/train_musicgen_edm_uncond/train/outputs`\n",
        "- the name of my training run (\"YOUR_TRAINING_RUN\") is \"train\""
      ],
      "metadata": {
        "id": "yG68hiK5vxA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the .jsonl\n",
        "\n",
        "if autolabelled:\n",
        "    print('skip this cell, move on to the .yaml')\n",
        "    exit(0)\n",
        "\n",
        "# if you have a .json file for each audio file sharing the same filename, set this variable to True\n",
        "use_existing_json = False\n",
        "\n",
        "# mount google drive to access dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "# make sure the .jsonl has a place to go\n",
        "os.makedirs(\"/content/audiocraft/egs/train\", exist_ok=True)\n",
        "os.makedirs(\"/content/audiocraft/egs/eval\", exist_ok=True)\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/samples/train_musicgen_edm_uncond/train/outputs\"\n",
        "train_manifest_path = \"/content/audiocraft/egs/train/data.jsonl\"\n",
        "eval_manifest_path = \"/content/audiocraft/egs/eval/data.jsonl\"\n",
        "\n",
        "dataset_len = 0\n",
        "train_len = 0\n",
        "eval_len = 0\n",
        "\n",
        "train_file = open(train_manifest_path, 'w')\n",
        "eval_file = open(eval_manifest_path, 'w')\n",
        "\n",
        "for filename in os.listdir(dataset_folder):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        dataset_len += 1\n",
        "\n",
        "        if use_existing_json:\n",
        "            json_filepath = os.path.splitext(filename)[0] + \".json\"\n",
        "            if os.path.exists(json_filepath):\n",
        "                with open(json_filepath, 'r') as json_file:\n",
        "                    entry = json.load(json_file)\n",
        "            else:\n",
        "                print(f'error loading json: could not find {json_filepath}')\n",
        "        else:\n",
        "\n",
        "            # empty fields for now, alter as needed to match your metadata.\n",
        "            # all this does is make sure each file loads and trains semi-unconditionally\n",
        "            entry = {\n",
        "                \"key\": \"\",\n",
        "                \"artist\": \"\",\n",
        "                \"sample_rate\": 44100,\n",
        "                \"file_extension\": \"wav\",\n",
        "                \"description\": \"\",\n",
        "                \"keywords\": \"\",\n",
        "                \"duration\": 30.0,\n",
        "                \"bpm\": \"\",\n",
        "                \"genre\": \"electronic\",\n",
        "                \"title\": \"\",\n",
        "                \"name\": \"\",\n",
        "                \"instrument\": \"\",\n",
        "                \"moods\": [],\n",
        "                \"path\": os.path.join(dataset_folder, filename),\n",
        "            }\n",
        "\n",
        "        if random.random() < 0.85:\n",
        "            train_len += 1\n",
        "            train_file.write(json.dumps(entry) + '\\n')\n",
        "        else:\n",
        "            eval_len += 1\n",
        "            eval_file.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "train_file.close()\n",
        "eval_file.close()\n",
        "\n",
        "print(f'dataset length: {dataset_len} audio clips')\n",
        "print(f'train length: {train_len} audio clips')\n",
        "print(f'eval length: {eval_len} audio clips')"
      ],
      "metadata": {
        "id": "-2PGiow_wGZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the .yaml\n",
        "\n",
        "config_path = \"/content/audiocraft/config/dset/audio/train.yaml\"\n",
        "\n",
        "# point to the folders that your .jsonl is in\n",
        "data_path = \"egs/train\"\n",
        "eval_data_path = \"egs/eval\"\n",
        "\n",
        "package = \"package\" # yay python not letting me put #@.package in a string :/\n",
        "yaml_contents = f\"\"\"#@{package} __global__\n",
        "\n",
        "datasource:\n",
        "  max_channels: 2\n",
        "  max_sample_rate: 44100\n",
        "\n",
        "  evaluate: {eval_data_path}\n",
        "  generate: {data_path}\n",
        "  train: {data_path}\n",
        "  valid: {eval_data_path}\n",
        "\"\"\"\n",
        "\n",
        "with open(config_path, 'w') as yaml_file:\n",
        "    yaml_file.write(yaml_contents)"
      ],
      "metadata": {
        "id": "br7VuO_NvuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training\n",
        "\n",
        "musicgen uses a thing called `dora` to launch the training run with a given solver, dataset, hyperparams, etc etc. if you've used anything like `accelerate`, it's like that. the command should be fairly easy to figure out from the given example.\n",
        "\n",
        "The below command is starting a finetuning run on the pretrained \"small\" model. Training from scratch is beyond the scope of this notebook, but shouldn't be too hard, just a *lot* of compute. Resuming from your finetuned chedkpoints will be covered later.\n",
        "\n",
        "Some info about VRAM requirements and training time:\n",
        "- It appears you can't train \"medium\" or \"large\" models on a single colab A100. They both OOM even with a batch size of 1. \"melody\" doesn't seem to load with anything i can pass to the `model/lm/model_scale=` param. You'll have to use \"small\"\n",
        "- here's the VRAM requirements with different batch sizes, using small model, 30s@44100 audios:\n",
        "\n",
        "```\n",
        "batch_size: VRAM\n",
        "1: 13.4 GB\n",
        "2: 14.6 GB\n",
        "4: 19.0 GB\n",
        "8: 27.5 GB\n",
        "12: 35.1 GB\n",
        "16: OOM\n",
        "```\n",
        "\n",
        "I did a training run with ~5000 of those samples, and it took roughly 90 minutes for 1 epoch to complete (on an A100). A checkpoint gets saved every epoch, more on this later. With a smaller dataset, you might have faster train times, I'm not sure (since the musicgen code says dataset size is disconnected from epoch length for this repo specifically, but they also say 1 epoch is roughly 30 minutes, so I can't take their word for it)\n",
        "\n",
        "You'll probably need quite a few epochs to get good results, I trained it for 4 epochs (about 6 hours) and the quality is still not great.\n",
        "\n",
        "NOTE: These numbers were from a previous test, before I updated the training parameters to be more efficient on a single GPU. There should be a ~50% speedup vs previous version. musicgen uses dadaw optimizer by default, which caches tokens, good for large runs on multiple gpus, but is less efficient on a single colab gpu.\n",
        "\n",
        "My example code stops after 5 epochs. change this number to suit your needs, I kept it here to mitigate losing my instance on crash. My personal version saves the `.th` to drive and resumes run, so if colab crashes while I'm afk, I can at most lose 5 epochs of compute.\n",
        "\n",
        "## example:"
      ],
      "metadata": {
        "id": "us8clCVnv1IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env USER=lyra\n",
        "# CHANGE THIS\n",
        "\n",
        "command = (\n",
        "    \"dora run solver=musicgen/musicgen_base_32khz\"\n",
        "    \" model/lm/model_scale=small\"\n",
        "    \" continue_from=//pretrained/facebook/musicgen-small\"\n",
        "    \" conditioner=text2music\"\n",
        "    \" dset=audio/train\"\n",
        "    \" dataset.num_workers=2\"\n",
        "    \" dataset.valid.num_samples=1\"\n",
        "    \" dataset.batch_size=2\" # CHANGE THIS\n",
        "    \" schedule.cosine.warmup=8\"\n",
        "    \" optim.optimizer=adamw\" # uses dadaw by default, which is worse for single-gpu runs\n",
        "    \" optim.lr=1e-4\"\n",
        "    \" optim.epochs=5\" # stops training after 5 epochs- change this\n",
        "    \" optim.adam.weight_decay=0.01\"\n",
        ")\n",
        "\n",
        "!{command}"
      ],
      "metadata": {
        "id": "VcrtDHggv3qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save, load, export\n",
        "\n",
        "Every epoch, the trainer saves a `checkpoint.th` file to `tmp/audiocraft_USER/xps/YOUR_RUN_SIG/checkpoint.th`.\n",
        "\n",
        "`USER` is set by `%env USER=lyra` from earlier, and `YOUR_RUN_SIG` should look something like \"2312e8a4\", and is found in the output of the training command, in a line that looks like this near the top:\n",
        "\n",
        "```\n",
        "[08-10 08:17:06][flashy.solver][INFO] - Instantiating solver MusicGenSolver for XP 2312e8a4\n",
        "[08-10 08:17:06][flashy.solver][INFO] - All XP logs are stored in /tmp/audiocraft_lyra/xps/2312e8a4\n",
        "```\n",
        "see https://github.com/facebookresearch/audiocraft/blob/main/docs/TRAINING.md#a-small-introduction-to-dora for more details on run signatures\n",
        "\n",
        "the `.th` file can't be loaded into musicgen for inference, but is required to resume a training run.\n",
        "\n",
        "to get a model that the generator can use, audiocraft comes with an export function. using it requires passing a model signature (unsure about passing a .th), so you'll have to do it in the same runtime as training.\n",
        "\n",
        "The export function makes two .bin files in the same folder: `state_dict.bin` and `compression_state_dict.bin`. the file sizes (for the small finetunes, at least) are ~800 MB and 1 KB respectively. These seem to load on top of the pretrained models, leading to lower file size than the original checkpoints. For reference, the small base model is ~2.5 GB, and the `checkpoint.th` is ~8.8 GB.\n",
        "\n",
        "loading the finetune involves passing the folder containing both `.bin` files to `MusicGen.get_pretrained()`, just like loading the base models.\n",
        "\n",
        "## the tricky parts\n",
        "\n",
        "colab's filesystem is temporary. this means if the runtime crashes before you've saved your `.th`, all that training is gone. the training code will continuously run, so there's no easy way to interrupt it to save the checkpoint before continuing. You'll need to monitor your training run, and make sure you have enough compute credits! it's always safer to stop, save, and resume than to hope it just keeps working.\n",
        "\n",
        "one way to try to get around this is exporting in a try/except block, so if it fails to load an audio file while you're away, at least you get the last checkpoint. (untested!) example at the end\n",
        "\n",
        "##examples:"
      ],
      "metadata": {
        "id": "9zlPbcLjv4qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting .bin files from a training run:\n",
        "\n",
        "from audiocraft.utils import export\n",
        "from audiocraft import train\n",
        "\n",
        "sig = \"2312e8a4\"\n",
        "\n",
        "# from https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md#importing--exporting-models\n",
        "xp = train.main.get_xp_from_sig(sig)\n",
        "export.export_lm(xp.folder / 'checkpoint.th', '/content/checkpoints/finetune/state_dict.bin')\n",
        "export.export_pretrained_compression_model('facebook/encodec_32khz', '/content/checkpoints/finetune/compression_state_dict.bin')\n"
      ],
      "metadata": {
        "id": "uvtz2uKm59AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a finetune for inference:\n",
        "\n",
        "from audiocraft.models import MusicGen\n",
        "musicgen = MusicGen.get_pretrained('/content/checkpoints/finetune')"
      ],
      "metadata": {
        "id": "cOlUoUmh5_5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resuming a run:\n",
        "\n",
        "sig = \"f44853c9\"\n",
        "\n",
        "command = (\n",
        "    \"dora run solver=musicgen/musicgen_base_32khz\"\n",
        "    \" model/lm/model_scale=small\"\n",
        "\n",
        "    # you can continue a run this way, if the filesystem still exists:\n",
        "    f\" continue_from=//SIG/{sig}\"\n",
        "\n",
        "    # or you can save the .th file, load it in a new runtime, and resume from just it:\n",
        "    f\" continue_from=/tmp/audiocraft_lyra/xps/{sig}/checkpoint.th\"\n",
        "\n",
        "    \" conditioner=text2music\"\n",
        "    \" dset=audio/train\"\n",
        "    \" dataset.num_workers=2\"\n",
        "    \" dataset.valid.num_samples=1\"\n",
        "    \" dataset.batch_size=2\"\n",
        "    \" schedule.cosine.warmup=8\"\n",
        "    \" optim.optimizer=adamw\" # uses dadaw by default, which is worse for single-gpu runs\n",
        "    \" optim.lr=1e-4\"\n",
        "    \" optim.epochs=5\" # stops training after 5 epochs- change this\n",
        "    \" optim.adam.weight_decay=0.01\"\n",
        ")\n",
        "\n",
        "!{command}"
      ],
      "metadata": {
        "id": "3WkCSzDtv8ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the .th file to google drive for persistence:\n",
        "# it's ~8.8gb, so downloading from the colab filesystem is annoying. this is much easier\n",
        "# you can point directly to the checkpoint in google drive when resuming as well\n",
        "\n",
        "import shutil\n",
        "sig = \"f44853c9\"\n",
        "\n",
        "source_path = f'/tmp/audiocraft_lyra/xps/{sig}/checkpoint.th'\n",
        "destination_path = '/content/drive/MyDrive/musicgen_finetunes/checkpoints/'\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "shutil.copy(source_path, destination_path)"
      ],
      "metadata": {
        "id": "saZk_zzA5JVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to save checkpoint on crash!!\n",
        "sig = \"f44853c9\"\n",
        "\n",
        "try:\n",
        "    !{command}\n",
        "except:\n",
        "    import shutil\n",
        "    source_path = f'/tmp/audiocraft_lyra/xps/{sig}/checkpoint.th'\n",
        "    destination_path = '/content/drive/MyDrive/musicgen_finetunes/checkpoints/'\n",
        "    os.makedirs(destination_path, exist_ok=True)\n",
        "    shutil.copy(source_path, destination_path)"
      ],
      "metadata": {
        "id": "Xh61jbLQ7kcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate\n",
        "\n",
        "generating has been covered by many notebooks etc, but I'll include a few scripts here for different types of generating, including unconditional, text conditioned, sample continuation, pseudo stereo, multiband diffusion, and eventually more.\n",
        "\n",
        "note that melody is not included, since I cannot train the melody model with this script so it's beyond the scope of this notebook.\n",
        "\n",
        "for more info on using the multi-band diffusion model, read the docs here:\n",
        "https://github.com/facebookresearch/audiocraft/blob/main/docs/MBD.md\n",
        "\n",
        "Note: if you want to load the model from drive so you can use these examples without running the training script first, change `content/checkpoints/finetune` in the first cell to the path to the drive folder that your two `.bin` files are saved in. in the exporting example, it was `content/drive/MyDrive/musicgen_finetunes/checkpoints/`."
      ],
      "metadata": {
        "id": "UjevANVKv_dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from audiocraft.data.audio import audio_write\n",
        "import IPython.display as ipd\n",
        "from audiocraft.models import MusicGen\n",
        "import numpy as np\n",
        "\n",
        "# load your finetune\n",
        "musicgen = MusicGen.get_pretrained('/content/checkpoints/finetune')\n",
        "musicgen.set_generation_params(duration=16)"
      ],
      "metadata": {
        "id": "yLsA5LvCv-hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: unconditional generation\n",
        "\n",
        "wavs = musicgen.generate_unconditional(4)\n",
        "\n",
        "# save and display generated audio\n",
        "for idx, one_wav in enumerate(wavs):\n",
        "    audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))"
      ],
      "metadata": {
        "id": "zReKGkmKpAZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: text guided generation\n",
        "\n",
        "wavs = musicgen.generate([\n",
        "    'disco',\n",
        "    'slide guitar bluegrass',\n",
        "    'breakbeat, amen break',\n",
        "    'epic orchestral strings'\n",
        "])\n",
        "\n",
        "# save and display generated audio\n",
        "for idx, one_wav in enumerate(wavs):\n",
        "    audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))"
      ],
      "metadata": {
        "id": "-ZMKusYNpYzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions for handling sample input and continations\n",
        "# RUN THIS BEFORE RUNNING THE NEXT CELLS!\n",
        "\n",
        "!pip install julius\n",
        "\n",
        "import julius, torch\n",
        "\n",
        "def normalize_audio(audio_data):\n",
        "    max_value = torch.max(torch.abs(audio_data))\n",
        "    audio_data /= max_value\n",
        "    return audio_data\n",
        "\n",
        "def convert_audio_channels(wav: torch.Tensor, channels: int = 2) -> torch.Tensor:\n",
        "    *shape, src_channels, length = wav.shape\n",
        "    if src_channels == channels:\n",
        "        pass\n",
        "    elif channels == 1:\n",
        "        wav = wav.mean(dim=-2, keepdim=True)\n",
        "    elif src_channels == 1:\n",
        "        wav = wav.expand(*shape, channels, length)\n",
        "    elif src_channels >= channels:\n",
        "        wav = wav[..., :channels, :]\n",
        "    else:\n",
        "        raise ValueError('The audio file has less channels than requested but is not mono.')\n",
        "    return wav\n",
        "\n",
        "def convert_audio(wav: torch.Tensor, from_rate: float, to_rate: float, to_channels: int) -> torch.Tensor:\n",
        "    wav = julius.resample_frac(wav, int(from_rate), int(to_rate))\n",
        "    wav = convert_audio_channels(wav, to_channels)\n",
        "    return wav\n",
        "\n",
        "# runs musicgen.generate_continuation in 30s chunks and appends them until it reaches generation_length\n",
        "\n",
        "def generate_audio_continuation(musicgen, sample, generation_length, segment_length=30, overlap=10):\n",
        "    overlap_samples = overlap * 32000\n",
        "    segment_samples = segment_length * 32000\n",
        "    output = np.array([])\n",
        "    output = np.concatenate((output, sample.cpu().squeeze().numpy().astype(np.float32)))\n",
        "    init_length = len(output) / 32000\n",
        "\n",
        "    while len(output) / 32000 < generation_length:\n",
        "        musicgen.set_generation_params(duration=segment_length)\n",
        "        prompt = torch.tensor(np.array([output[-overlap_samples:]]), dtype=torch.float32)\n",
        "        res = musicgen.generate_continuation(prompt=prompt, prompt_sample_rate=32000)\n",
        "        res = res.cpu().squeeze().numpy().astype(np.float32)\n",
        "        output = np.concatenate((output, res[overlap_samples:]))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "LVXEuvhnr-lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: sample continuation\n",
        "# run the helper functions cell or this won't work!\n",
        "\n",
        "# upload your file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "input_audio_filename = next(iter(uploaded.keys()))\n",
        "sample, sample_sr = torchaudio.load(input_audio_filename)\n",
        "sample = normalize_audio(sample)\n",
        "sample = convert_audio(sample, sample_sr, 32000, 1)\n",
        "\n",
        "# generate\n",
        "wav = generate_audio_continuation(musicgen, sample, 60)\n",
        "\n",
        "# save and display generated audio\n",
        "audio_write('continuation', output.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "ipd.display(ipd.Audio(output, rate=32000))"
      ],
      "metadata": {
        "id": "O-urbQ1rp0zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: long generations (self-continuation)\n",
        "# run the helper functions cell or this won't work!\n",
        "\n",
        "# this is unconditional for the example, swap in text guidance as needed.\n",
        "wavs = musicgen.generate_unconditional(4)\n",
        "\n",
        "# continuations only work on one sample at a time\n",
        "for idx, wav in enumerate(wavs):\n",
        "\n",
        "    wav = generate_audio_continuation(musicgen, wav, 60)\n",
        "\n",
        "    audio_write(f'{idx}', wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    ipd.display(ipd.Audio(wav.cpu(), rate=32000))"
      ],
      "metadata": {
        "id": "ABzE8Jyyr0Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 6: multiband diffusion decoder\n",
        "\n",
        "from audiocraft.models import MusicGen, MultiBandDiffusion\n",
        "mbd = MultiBandDiffusion.get_mbd_musicgen()\n",
        "\n",
        "# use mbd to generate the audio from the codebook tokens\n",
        "wavs, tokens = musicgen.generate_unconditional(4, return_tokens=True)\n",
        "wavs_diffusion = mbd.tokens_to_wav(tokens)\n",
        "\n",
        "# save and display generated audio\n",
        "for idx, one_wav in enumerate(wavs):\n",
        "    audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    audio_write(f'{idx}_diffusion', wavs_diffusion[idx].cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "\n",
        "    print('default decoder:')\n",
        "    ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))\n",
        "    print('multiband diffusion:')\n",
        "    ipd.display(ipd.Audio(wavs_diffusion[idx].cpu().cpu(), rate=32000))"
      ],
      "metadata": {
        "id": "X3L0vDwKvm6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# local installation for inference\n",
        "\n",
        "this section assumes you have a GPU with 8gb of vram. it only covers inference, since you cannot train on only 8gb vram. if you have the gpu spec to train, this should get you started but you may have to figure out the details yourself (i cannot test it, my gpu is 8gb). I'll assume you have python installed already.\n",
        "\n",
        "## step 1 - environment\n",
        "\n",
        "I use miniconda for managing environments for each project. you can download it here: https://docs.conda.io/en/main/miniconda.html\n",
        "\n",
        "once it's installed, run:\n",
        "\n",
        "```\n",
        "conda create --name musicgen\n",
        "conda activate musicgen\n",
        "```\n",
        "\n",
        "make a folder for your musicgen projects to live. you'll want to `cd` to this folder before running the commands in the next step.\n",
        "\n",
        "## step 2 - audiocraft\n",
        "\n",
        "now you're in your environment and can start installing.\n",
        "\n",
        "I'm going to assume you have git installed, if not, https://gitforwindows.org/ (other platforms- find your own. it won't be hard).\n",
        "\n",
        "You should recognize these commands from the top of this notebook:\n",
        "\n",
        "```\n",
        "git clone https://github.com/facebookresearch/audiocraft.git\n",
        "cd audiocraft\n",
        "pip install -e .\n",
        "pip install dora-search julius\n",
        "```\n",
        "\n",
        "running these out of the box should install a bunch of dependencies, but it'll give you a pytorch-cpu version with no GPU access by default. You'll need a CUDA version to actually run this.\n",
        "\n",
        "## step 3 - torch with cuda\n",
        "\n",
        "You will need cuda for this to work. if you don't have it, go get it here: https://developer.nvidia.com/cuda-downloads\n",
        "\n",
        "`pip install --upgrade torch --extra-index-url https://download.pytorch.org/whl/cu117`\n",
        "\n",
        "You can't install torch with cuda *first*, because audiocraft will overwrite it during install.\n",
        "\n",
        "## step 4 - make a script and run\n",
        "\n",
        "at this point, everything is installed and you can do whatever with the environment. here's an example script you can use to make sure everything is loaded and working properly:\n",
        "\n",
        "```\n",
        "import torchaudio\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "\n",
        "print('loading model...')\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "model.set_generation_params(duration=8)\n",
        "\n",
        "print('generating...')\n",
        "wav = model.generate_unconditional(4)\n",
        "\n",
        "print('saving...')\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    audio_write(f'{idx}', one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "\n",
        "print('done!')\n",
        "```\n",
        "\n",
        "save this as `example.py` and run it, and you should get a `1.wav` file after a little bit. I won't go into too much detail since I figure you know how to run a python script.\n",
        "\n",
        "if you want to use your finetunes, go ahead and make a folder for them to live (perhaps `checkpoints/finetune_1`, `checkpoints/finetune_2`, etc), and use the examples given above to load them from your folder.\n",
        "\n",
        "If you're trying to train this with `dora` on Windows, you'll need to make some modifications:\n",
        "\n",
        "\n",
        "> in audiocraft/utils/cluster.py: comment out lines 28-40\n",
        "\n",
        "> in audiocraft/train.py: comment out line 110\n",
        "\n",
        "> in the above code:\n",
        "\n",
        "```\n",
        "command = (\n",
        "    \"dora -P audiocraft run\"\n",
        "    ...\n",
        "```\n",
        "Note that the above command is expecting to be executed from the audiocraft directory, looking back one folder: `C:/...project_folder/audiocraft>python ../train_musicgen.py` where `train_musicgen.py` is in `project_folder` and contains the above code.\n",
        "\n",
        "\n",
        "DISCLAIMER: I have run similar commands successfully, but not exactly as written in this notebook. Until I have a chance to run this with a clean slate new environment to test it out, some parts may not work. If something is broken or needs changing, please let me know!\n",
        "\n",
        "I'm `lyraaaa_` on discord, and `@bleepybloops` on twitter/X."
      ],
      "metadata": {
        "id": "RUjdT47y0hJR"
      }
    }
  ]
}